Replace this file with the answers to the essay questions here.
----------------------------------------------------------------------

1. You will observe that a large portion of the terms in the dictionary are numbers. However, we normally do not use numbers as query terms to search. Do you think it is a good idea to remove these number entries from the dictionary and the postings lists? Can you propose methods to normalize these numbers? How many percentage of reduction in disk storage do you observe after removing/normalizing these numbers?

- Depends on domain
- Since reuters, people who search this data may be interested in searching for things associated with dates. Eg. "2012 AND elections AND us"
-

2. What do you think will happen if we remove stop words from the dictionary and postings file? How does it affect the searching phase?

Removing stop words will help with the size of the dictionary and the postings file (more for the postings file).




3. The NLTK tokenizer may not correctly tokenize all terms. What do you observe from the resulting terms produced by sent_tokenize() and word_tokenize()? Can you propose rules to further refine these results?

The tokenizer keeps the hyphen. So queries need to keep the hyphen. Its smart enough to keep the punctuation (commas, periods) for numbers and not others.
Slashes are not tokenized probably.
